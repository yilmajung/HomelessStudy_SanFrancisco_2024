{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapillary as mly\n",
    "from mapillary.models.geojson import GeoJSON\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapillary API token\n",
    "my_token = 'MLY|25519453337668549|19ddb43d09d1996ff1ceaec8b0693efc'\n",
    "mly.interface.set_access_token(my_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bounding box info (DC)\n",
    "df_bbox = pd.read_csv('/content/drive/MyDrive/Homeless_SF/df_bbox_99.csv')\n",
    "\n",
    "# Select the rows with GEOID starting with 06075 (San Francisco)\n",
    "df_bbox['GEOID'] = df_bbox['GEOID'].astype(str)\n",
    "df_bbox['GEOID'] = df_bbox['GEOID'].apply(lambda x: x.zfill(12))\n",
    "df_bbox = df_bbox[df_bbox['GEOID'].str.startswith('06075')]\n",
    "\n",
    "# Reset index\n",
    "df_bbox.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop the first column Unnamed: 0\n",
    "df_bbox = df_bbox.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Separate 'swen_edges' into four columns\n",
    "df_bbox[['south','west','north','east']] = df_bbox['swne_edges'].apply(lambda x: pd.Series(str(x).strip('()').replace(\" \",\"\").split(',')))\n",
    "df_bbox[['south','west','north','east']] = df_bbox[['south','west','north','east']].astype(float)\n",
    "\n",
    "# Create bboxid adding row_num and col_num\n",
    "df_bbox['bboxid'] = 'bbox_' + df_bbox['row_num'].astype(str) + '_' + df_bbox['col_num'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create safe_append function to add np.nan for missing query\n",
    "def safe_append(data, key, append_to, fallback=np.nan):\n",
    "\n",
    "    try:\n",
    "        append_to.append(data[key])\n",
    "\n",
    "    except (AttributeError, KeyError):\n",
    "        append_to.append(fallback)\n",
    "\n",
    "\n",
    "# Create a function to extract image info\n",
    "def extract_mapillary_image_info(df_bbox, resolution=1024):\n",
    "\n",
    "    # Initialize lists to store image info\n",
    "    image_info = {'image_id': [], 'user_id': [], 'sequence_id': [], 'image_coord': [], 'image_timestamp_unix': [], 'image_url': [],\n",
    "                  'image_angle': [], 'geoid': [], 'bboxid': []}\n",
    "\n",
    "    for idx, row in tqdm(df_bbox.iterrows(), total=df_bbox.shape[0]):\n",
    "        # Construct bounding box dictionary\n",
    "        bbox = {k: row[k] for k in ['west', 'south', 'east', 'north']}\n",
    "        print(f'{idx+1} / {df_bbox.shape[0]}')\n",
    "\n",
    "        # Fetch images data within the bounding box\n",
    "        images_data = json.loads(mly.interface.images_in_bbox(bbox, image_type='flat'))\n",
    "\n",
    "        for feature in images_data['features']:\n",
    "            properties = feature['properties']\n",
    "            geometry = feature['geometry']\n",
    "\n",
    "            # Safely append values to respective lists\n",
    "            safe_append(properties, 'id', image_info['image_id'])\n",
    "            safe_append(properties, 'creator_id', image_info['user_id'])\n",
    "            safe_append(properties, 'sequence_id', image_info['sequence_id'])\n",
    "            safe_append(geometry, 'coordinates', image_info['image_coord'])\n",
    "            safe_append(properties, 'captured_at', image_info['image_timestamp_unix'])\n",
    "            safe_append(properties, 'compass_angle', image_info['image_angle'])\n",
    "            image_info['geoid'].append(row['GEOID'])\n",
    "            image_info['bboxid'].append(row['bboxid'])\n",
    "\n",
    "            # Extract image URL\n",
    "            image_id = properties.get('id', np.nan)\n",
    "\n",
    "            if np.isnan(image_id):\n",
    "                image_info['umage_url'].append(np.nan)\n",
    "            else:\n",
    "                try:\n",
    "                    url = mly.interface.image_thumbnail(image_id=image_id, resolution=resolution)\n",
    "                    image_info['image_url'].append(url)\n",
    "                except:\n",
    "                    image_info['image_url'].append(np.nan)\n",
    "\n",
    "    # Create a dataframe\n",
    "    df_images = pd.DataFrame(image_info)\n",
    "    return df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "num_chunks = 100\n",
    "chunks = np.array_split(df_bbox, num_chunks)\n",
    "\n",
    "c = 0 # pick up from where the previous session stopped\n",
    "\n",
    "for m, chunk in enumerate(chunks[c:100]):\n",
    "    df_images = extract_mapillary_image_info(chunk, resolution=1024)\n",
    "    df_images.to_csv(f'/content/drive/MyDrive/Homeless_SF/image_url/df_mapillary_{m+c}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
