{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the GPmodel with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/df_cleaned_10292024.csv')\n",
    "\n",
    "# Separate df into training and testing data\n",
    "df_train = df[df['ground_truth'].notnull()]\n",
    "df_test = df[df['ground_truth'].isnull()]\n",
    "\n",
    "# Shuffle the data\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Latent Embedding Kernel and combine with other features\n",
    "class LatentEmbeddingAndFeatureKernel(gpytorch.kernels.Kernel):\n",
    "    def __init__(self, num_areas, embedding_dim, feature_kernel, **kwargs):\n",
    "        super(LatentEmbeddingAndFeatureKernel, self).__init__(**kwargs)\n",
    "        \n",
    "        # Learnable embeddings for each area (discrete)\n",
    "        self.embedding = torch.nn.Embedding(num_areas, embedding_dim)\n",
    "        \n",
    "        # Kernel for continuous features\n",
    "        self.feature_kernel = feature_kernel\n",
    "    \n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        # Split x1 and x2 into bboxid and continuous features\n",
    "        bboxid_x1, features_x1 = x1[:, 0].long(), x1[:, 1:]\n",
    "        bboxid_x2, features_x2 = x2[:, 0].long(), x2[:, 1:]\n",
    "\n",
    "        # Compute the embeddings for bboxid\n",
    "        embed_x1 = self.embedding(bboxid_x1)\n",
    "        embed_x2 = self.embedding(bboxid_x2)\n",
    "\n",
    "        # Standardize the continuous features\n",
    "        features_x1 = (features_x1 - features_x1.mean(dim=0)) / features_x1.std(dim=0)\n",
    "        features_x2 = (features_x2 - features_x2.mean(dim=0)) / features_x2.std(dim=0)\n",
    "\n",
    "        # Combine embeddings with the continuous features\n",
    "        combined_x1 = torch.cat([embed_x1, features_x1], dim=-1)\n",
    "        combined_x2 = torch.cat([embed_x2, features_x2], dim=-1)\n",
    "\n",
    "        # Apply the RBF kernel to the combined inputs\n",
    "        if diag:\n",
    "            # Return only the diagonal elements when requested\n",
    "            return self.feature_kernel(combined_x1, combined_x2, diag=True)\n",
    "        else:\n",
    "            # Return the full covariance matrix when diagonal is not requested\n",
    "            return self.feature_kernel(combined_x1, combined_x2)\n",
    "\n",
    "    def diag(self, x):\n",
    "        # Handle diagonal requests by passing `diag=True` to the forward method\n",
    "        return self.forward(x, x, diag=True)\n",
    "        \n",
    "        # # Apply a standard kernel to the combined inputs (embeddings + continuous features)\n",
    "        # return self.feature_kernel(combined_x1, combined_x2)\n",
    "\n",
    "# Define the GP Model with Poisson Likelihood\n",
    "class GPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, num_areas):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "\n",
    "        # Define the kernel: latent embedding for area codes + kernel for temperature and demographic features\n",
    "        feature_kernel = gpytorch.kernels.RBFKernel(ard_num_dims=embedding_dim + 7) # 7  additional features\n",
    "        self.covar_module = LatentEmbeddingAndFeatureKernel(num_areas, embedding_dim, feature_kernel)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "# Define the Poisson likelihood for count data (number of tents)\n",
    "class PoissonLikelihood(gpytorch.likelihoods.Likelihood):\n",
    "    def forward(self, function_samples, *args, **kwargs):\n",
    "        # Apply the log-link function (exponentiate the latent GP)\n",
    "        return torch.distributions.Poisson(rate=function_samples.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with best hyperparameters\n",
    "embedding_dim = 3\n",
    "batch_size = 1000\n",
    "num_inducing_points = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Get the number of unique areas and days\n",
    "num_areas = df_train['bboxid'].nunique()\n",
    "num_days = df_train['timestamp'].nunique()\n",
    "\n",
    "# Create a bboxid tensor\n",
    "bboxid_tensor = torch.tensor(df_train['bboxid'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "\n",
    "# Create a temperature tensor\n",
    "temperature_tensor = torch.tensor(df_train[['max','min','precipitation']].values, dtype=torch.float32)\n",
    "\n",
    "# Create a demographic tensor\n",
    "demographic_tensor = torch.tensor(df_train[['total_population','white_ratio','black_ratio','hh_median_income']].values, dtype=torch.float32)\n",
    "\n",
    "# Create a ground truth tensor\n",
    "target_tensor = torch.tensor(df_train['ground_truth'].values, dtype=torch.float32)\n",
    "\n",
    "# Prepare the dataset\n",
    "train_dataset = TensorDataset(torch.cat([bboxid_tensor.unsqueeze(-1), temperature_tensor, demographic_tensor], dim=-1), target_tensor)\n",
    "\n",
    "# Set up a DataLoader for mini-batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([263883])\n",
      "torch.Size([263883, 3])\n",
      "torch.Size([263883, 4])\n",
      "torch.Size([263883])\n"
     ]
    }
   ],
   "source": [
    "print(bboxid_tensor.shape)\n",
    "print(temperature_tensor.shape)\n",
    "print(demographic_tensor.shape)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4377"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['bboxid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4377"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxid_tensor.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263883"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/100 - Loss: 1.0771100521087646\n",
      "Iteration 10/100 - Loss: 1.0547429323196411\n",
      "Iteration 20/100 - Loss: 1.0673983097076416\n",
      "Iteration 30/100 - Loss: 1.0710989236831665\n",
      "Iteration 40/100 - Loss: 1.0386900901794434\n",
      "Iteration 50/100 - Loss: 1.043838620185852\n",
      "Iteration 60/100 - Loss: 1.0705124139785767\n",
      "Iteration 70/100 - Loss: 1.0593180656433105\n",
      "Iteration 80/100 - Loss: 1.0335173606872559\n",
      "Iteration 90/100 - Loss: 1.0617444515228271\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the bboxid tensor, temperature tensor, and demographic tensor into a single tensor\n",
    "train_x = torch.cat([bboxid_tensor.unsqueeze(-1), temperature_tensor, demographic_tensor], dim=-1)\n",
    "\n",
    "# Define inducing points for the sparse approximation (subset of training data)\n",
    "# Randomly select inducing points\n",
    "inducing_points = train_x[torch.randperm(train_x.size(0))[:num_inducing_points]] \n",
    "\n",
    "# Initialize model and likelihood\n",
    "model = GPModel(inducing_points, num_areas=num_areas)\n",
    "#model = model.to(device)\n",
    "likelihood = PoissonLikelihood()\n",
    "#likelihood = likelihood.to(device)\n",
    "\n",
    "# Training the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=learning_rate)\n",
    "\n",
    "# Loss function: Variational ELBO\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=len(train_dataset))\n",
    "\n",
    "# Training loop\n",
    "training_iterations = 100\n",
    "for j in range(training_iterations):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = -mll(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if j % 10 == 0:\n",
    "        print(f'Iteration {j}/{training_iterations} - Loss: {loss.item()}')\n",
    "\n",
    "    # Save the model\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss.item(),\n",
    "}\n",
    "torch.save(checkpoint, f'checkpoints/checkpoint_indpts_{num_inducing_points}_embdim_{embedding_dim}.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('variational_strategy.inducing_points', tensor([[ 3.7840e+03,  5.9684e+01,  5.1546e+01,  ...,  3.3925e-01,\n",
      "         -8.0264e-01,  1.6471e+05],\n",
      "        [ 3.4690e+03,  6.0146e+01,  4.9315e+01,  ...,  7.8183e-01,\n",
      "         -1.1185e+00,  6.5694e+04],\n",
      "        [ 3.9160e+03,  7.2310e+01,  5.5366e+01,  ...,  1.0520e+00,\n",
      "         -1.5606e+00,  1.2900e+05],\n",
      "        ...,\n",
      "        [ 3.0410e+03,  5.7748e+01,  5.6745e+01,  ..., -2.0596e+00,\n",
      "          1.3280e+00,  1.2152e+05],\n",
      "        [ 2.6300e+03,  6.4484e+01,  5.2703e+01,  ...,  1.1623e+00,\n",
      "         -5.5317e-01,  1.4321e+05],\n",
      "        [ 2.8070e+03,  5.3306e+01,  4.8291e+01,  ...,  2.3263e+00,\n",
      "         -2.5910e-01,  9.3438e+04]])), ('variational_strategy.variational_params_initialized', tensor(1)), ('variational_strategy.updated_strategy', tensor(True)), ('variational_strategy._variational_distribution.variational_mean', tensor([ 1.1589e+00,  1.5812e-01,  2.5162e-01,  2.8896e-01,  3.3758e-01,\n",
      "         2.9814e-01,  4.5029e-01, -2.7556e-02,  9.1977e-01, -3.9280e-02,\n",
      "         1.2965e-01, -9.3178e-02, -5.2400e-02,  2.9494e-01,  2.1179e-01,\n",
      "         1.1014e-01,  2.3764e-01, -3.0506e-01,  1.9467e-01,  3.7456e-01,\n",
      "         4.3732e-01,  4.9369e-03,  4.1870e-01, -1.4314e-01,  5.8126e-02,\n",
      "         2.3735e-01,  1.3824e-01, -9.8330e-01, -6.6108e-02,  3.3708e-01,\n",
      "        -1.0192e-01, -3.1100e-01, -7.6122e-01,  8.0244e-02, -4.4289e-01,\n",
      "         1.1014e-01, -2.2297e-01, -1.2180e-02, -2.9910e+00,  8.5402e-01,\n",
      "         3.1293e-01,  5.4112e-01, -1.5172e+00, -3.1391e-01, -4.2649e-02,\n",
      "         1.1578e-01,  7.4562e-02,  3.0383e-01,  5.4830e-02, -5.2499e-01,\n",
      "         2.8832e-02,  2.0748e-01, -5.0811e-01, -2.4766e-02,  1.1818e-01,\n",
      "         3.5010e-01, -4.6559e-01, -7.3848e-02,  1.4241e+00,  2.2912e-01,\n",
      "         3.3036e-01,  8.8392e-01, -2.0887e-02, -3.6538e-01, -8.6174e-01,\n",
      "         4.9804e-01, -3.0451e-02, -5.9808e-02, -8.5001e-01,  2.2980e-02,\n",
      "         3.2302e-01, -5.4290e-02, -4.5142e-02, -6.2088e-01, -7.7367e-02,\n",
      "         2.8134e-02, -6.0161e-01, -4.5515e-01, -1.4546e+00, -2.8972e-01,\n",
      "        -2.7689e-01, -6.8491e-02,  3.9446e-01,  6.6713e-01,  6.5231e-01,\n",
      "        -4.5531e-01, -1.0427e+00, -3.1351e-01,  7.0926e-01,  1.2903e-01,\n",
      "        -6.1090e-01,  2.7630e-01, -1.3008e-02, -3.5500e-01, -5.0588e-01,\n",
      "        -3.4136e-01, -3.3817e+00, -1.8203e+00, -1.3522e+00, -1.6146e+00,\n",
      "        -7.0866e-01,  2.5579e-01, -8.8819e-01,  6.9405e-02,  3.9500e-01,\n",
      "        -2.5305e-01, -1.6496e-01, -9.8640e-02,  2.6516e-01, -9.2008e-01,\n",
      "        -2.2594e-01, -1.5615e+00,  1.2444e-01,  3.6038e-01, -7.8049e-01,\n",
      "        -7.4976e-01, -2.1993e-01,  2.8694e-01, -7.0324e-01, -2.9847e-01,\n",
      "         6.2025e-01, -6.7491e-01, -4.4118e-01,  1.3629e-01, -4.0701e+00,\n",
      "        -1.3070e+00,  3.9515e-01, -5.0867e-01,  9.5781e-02, -1.0485e+00,\n",
      "         2.1608e-01,  9.5555e-02,  2.3885e-01,  2.1604e-01,  2.7599e-01,\n",
      "        -7.9508e-01, -2.3436e+00, -6.8469e-01, -9.9828e-01, -1.7924e-01,\n",
      "        -1.1750e+00, -3.6910e-01, -4.0810e-01,  2.4460e-01,  6.7280e-01,\n",
      "        -1.5004e-01, -9.0318e-01, -1.7766e-01,  1.7672e+00, -1.7806e-01,\n",
      "        -1.0047e+00, -1.0179e+00, -1.6354e-01,  8.0245e-01,  4.4906e-02,\n",
      "        -1.5253e-01, -9.5673e-01,  7.5815e-02, -8.7605e-02, -4.5992e-01,\n",
      "         1.0816e-01,  8.4254e-01, -1.2526e-01,  4.3424e-01, -3.3319e-01,\n",
      "         5.9721e-01,  2.4984e-01, -6.4099e-01, -6.4995e-02,  7.9465e-01,\n",
      "         6.7679e-01,  1.1118e+00, -6.7959e-01, -2.5572e+00, -1.2007e+00,\n",
      "        -8.8210e-02,  6.3424e-01,  9.3302e-01, -4.9966e-02,  7.0508e-01,\n",
      "        -2.4610e+00, -8.4489e-01, -3.3423e-01, -7.0066e-01,  4.8431e-01,\n",
      "        -3.2588e-01, -2.7644e-01,  2.2083e-01, -5.0468e+00,  4.2891e-01,\n",
      "        -1.9879e-01, -1.4346e+00,  1.7459e-01,  5.9231e-01,  3.1209e-01,\n",
      "        -1.1110e-01, -1.0433e+00, -3.5665e+00, -6.1621e+00, -8.4160e-01,\n",
      "         1.1746e+00, -9.5142e-01,  4.0629e-01,  9.5630e-01,  2.3077e+00,\n",
      "        -5.7432e-02, -7.9559e-01, -1.0815e+00,  3.5467e-01,  6.3751e-02,\n",
      "        -1.8689e-01,  1.8887e+00, -2.3803e-01, -1.1595e-01,  3.9031e-01,\n",
      "        -1.1378e+00,  5.0544e-01,  1.4844e+00,  1.5877e+00,  9.1777e-01,\n",
      "         6.6274e-01, -1.3212e+00,  1.6692e-01,  4.0277e-01,  9.1777e-01,\n",
      "         3.3410e-01, -2.1988e-01,  7.4012e-01,  1.0449e+00, -2.2108e-02,\n",
      "         2.8344e-01,  1.4678e+00,  1.5536e-01,  2.9795e-01, -3.3813e-01,\n",
      "        -3.2963e+00, -2.6065e+00, -6.3195e-01, -2.7665e-01, -2.7803e+00,\n",
      "         2.9381e-01, -1.1759e+00, -1.8849e+00,  1.2011e+00,  3.3098e-01,\n",
      "        -5.7414e-02, -7.6324e-01, -4.1159e-01, -2.9765e+00, -1.4642e-01,\n",
      "        -3.1710e-01, -1.3844e+00, -1.1735e+00,  8.0588e-01,  1.3462e+00,\n",
      "        -3.8768e+00,  2.7187e-01,  3.4546e-01, -3.0070e+00, -7.7557e-01,\n",
      "        -5.1040e-01, -1.3913e-01,  4.8991e-01,  8.9794e-01,  1.9990e-01,\n",
      "        -1.0797e+00, -1.9851e+00, -2.2471e-01, -3.0598e-01,  4.2306e-01,\n",
      "        -8.6534e-02, -3.7248e+00,  5.9142e-01, -3.0473e-01, -1.1348e+00,\n",
      "        -4.9404e+00,  3.8556e-02,  5.7851e-01, -2.4156e-01, -9.5052e-01,\n",
      "        -1.3949e-01, -9.7393e-02,  1.7379e+00, -9.2416e-01,  8.3174e-01,\n",
      "         2.4563e-01, -2.1661e+00,  6.7298e-01,  1.3925e+00,  6.3863e-02,\n",
      "         5.5143e-01, -7.0443e-01, -2.8757e-01, -2.3934e-01,  1.2842e-03,\n",
      "         2.7372e-01, -1.4990e+00, -3.3201e-01, -2.6267e-01,  4.0157e-01,\n",
      "        -5.7646e-01, -5.1099e-01,  1.2146e+00, -2.1713e-01, -4.1711e-01,\n",
      "        -6.4107e-01,  4.5725e-02,  4.6849e-02, -1.0913e+00, -5.8797e-02,\n",
      "        -1.0446e-01, -1.6646e-01,  9.0374e-02,  2.2710e-01, -2.1226e-01,\n",
      "        -5.8484e-01, -4.8618e-01,  1.1302e+00, -2.0343e+00, -3.9599e-01,\n",
      "         3.4085e-02,  4.4000e-02, -9.2762e-01, -4.1914e-01, -3.5750e-01,\n",
      "        -3.4428e-01,  6.6289e-01, -7.1303e-03, -1.6865e+00, -8.7111e-02,\n",
      "        -3.0231e-01,  1.4430e-01, -1.4790e-02,  5.2425e-01,  7.3180e-01,\n",
      "        -1.1323e-01,  1.6072e-01, -1.1636e+00, -6.9410e-01,  7.0024e-01,\n",
      "        -6.0104e-02,  1.9464e-01,  2.3068e-01, -4.6495e-01,  5.9564e-01,\n",
      "         1.9072e+00,  3.9269e-01, -5.3738e-01, -9.8357e-02, -3.7637e-01,\n",
      "        -1.9124e-01, -3.1413e-01, -2.1413e-01, -5.1849e-01, -8.0810e-01,\n",
      "        -5.5588e-01,  7.8842e-01,  3.5969e-02, -1.2340e+00,  1.4388e+00,\n",
      "         2.4452e-01,  3.7015e-01, -1.1371e+00, -1.1247e+00,  1.5878e+00,\n",
      "         2.1375e-01, -9.5198e-01,  2.9694e-02, -3.2958e+00, -2.3479e-01,\n",
      "         9.5878e-02, -5.2495e-01, -3.3637e+00,  6.8056e-01, -3.6693e-03,\n",
      "         8.2805e-02,  7.4877e-02,  1.8397e-01,  8.5228e-01, -2.1098e-01,\n",
      "        -1.4934e-01, -1.9156e-01,  3.6730e-01,  1.1019e-01, -4.2682e-02,\n",
      "        -9.1307e-01,  1.5920e+00, -1.1186e-01,  1.2767e-01,  5.5550e-01,\n",
      "         1.0201e-01, -1.8635e+00, -6.1945e-02,  2.5503e-01, -5.1964e-01,\n",
      "         5.9204e-01, -8.5060e-02, -5.4972e-01,  1.1859e-01,  9.7580e-01,\n",
      "        -9.6830e-02, -1.8669e-02,  7.0218e-02,  3.3522e-02,  4.3193e-02,\n",
      "        -3.0796e-01, -2.0093e+00, -1.6130e+00, -1.3070e-01,  3.4267e-01,\n",
      "        -1.4821e-02, -4.8810e-01, -2.2239e+00,  9.4476e-02, -2.7297e-02,\n",
      "        -1.1238e-01,  1.3670e-01, -1.0219e+00, -1.6848e-03, -2.8263e-01,\n",
      "        -8.8861e-01,  9.5819e-01,  3.2583e-01, -7.4080e-02,  1.1192e+00,\n",
      "        -1.2761e+00,  1.4697e+00, -5.6382e-01, -6.5853e-01,  8.3410e-03,\n",
      "         9.4582e-01,  3.6972e-01, -5.1514e-01, -2.1580e-01,  2.7078e-02,\n",
      "         2.3201e-01,  2.6069e-01, -4.3599e-01, -3.2085e+00,  1.5946e-02,\n",
      "        -1.0293e-01, -1.7052e-01, -1.6432e+00, -3.5125e-01, -2.0536e+00,\n",
      "        -5.6589e-01,  9.8101e-01,  7.3444e-02,  2.3016e-01, -1.7390e-01,\n",
      "         5.9332e-01,  8.2550e-02,  1.2215e-01, -3.5487e-02, -3.6493e+00,\n",
      "        -1.0784e+00,  9.0956e-03, -2.8239e-01,  2.0611e-01,  1.0396e+00,\n",
      "         3.5582e-01,  4.2116e-03, -7.9107e-02, -2.9321e-02, -2.5470e+00,\n",
      "         2.0019e+00, -2.0715e-01, -2.5185e+00,  5.9146e-02,  3.4350e-01,\n",
      "         2.6658e-02, -2.1232e-01,  3.4537e-03, -2.2029e-01, -7.9352e-01,\n",
      "        -3.5142e-01,  7.1329e-01,  8.5497e-02, -1.6227e+00, -3.8607e-01,\n",
      "        -9.0102e-01, -1.2786e-01, -1.4360e-01, -1.3362e+00,  1.1219e-01,\n",
      "         2.8420e-01, -1.4315e-02, -1.5039e-01,  1.4595e-01, -1.4728e+00,\n",
      "        -2.3037e+00, -4.0801e-01, -5.3500e-01,  5.4754e-02,  3.2679e-01,\n",
      "         6.6762e-02, -1.6383e-01,  1.1393e+00,  6.1943e-02, -5.6536e-01])), ('variational_strategy._variational_distribution.chol_variational_covar', tensor([[ 1.3520e-02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.3162e-02,  4.8334e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.8550e-02, -2.8257e-03,  2.9678e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 4.4346e-03, -1.4644e-02,  3.5364e-02,  ...,  9.0743e-01,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.2081e-02, -3.0218e-02, -5.9733e-03,  ..., -1.2004e-03,\n",
      "          9.9417e-01,  0.0000e+00],\n",
      "        [-1.8352e-02,  3.4766e-02, -2.9002e-04,  ...,  3.0834e-02,\n",
      "         -8.7448e-04,  8.3502e-01]])), ('covar_module.embedding.weight', tensor([[-0.2446,  4.2042,  3.8312],\n",
      "        [ 6.9215, -3.6629,  3.1949],\n",
      "        [-3.0792,  7.4758, -4.5446],\n",
      "        ...,\n",
      "        [-4.1235,  3.4501,  0.6782],\n",
      "        [-4.4570,  1.0228, -0.9022],\n",
      "        [ 2.9923, -1.0443, -1.3027]])), ('covar_module.feature_kernel.raw_lengthscale', tensor([[ 4.1217,  5.3563,  5.2276,  3.2261,  2.6541, 27.7489, 39.0960, 16.1345,\n",
      "         24.5798, 12.1393]])), ('covar_module.feature_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.feature_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(-1.0277))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and optimizer for prediction\n",
    "# Initialize model and likelihood\n",
    "model = GPModel(inducing_points, num_areas=num_areas)\n",
    "likelihood = PoissonLikelihood()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=learning_rate)\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('checkpoints/checkpoint_indpts_500_embdim_3.pth')\n",
    "\n",
    "# Restore model and optimizer states\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoissonLikelihood()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "likelihood.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_train['bboxid'].nunique())\n",
    "print(df_test['bboxid'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for Test set\n",
    "# Create a bboxid tensor\n",
    "bboxid_tensor_test = torch.tensor(df_test['bboxid'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "\n",
    "# Create a temperature tensor\n",
    "temperature_tensor_test = torch.tensor(df_test[['max','min','precipitation']].values, dtype=torch.float32)\n",
    "\n",
    "# Create a demographic tensor\n",
    "demographic_tensor_test = torch.tensor(df_test[['total_population','white_ratio','black_ratio','hh_median_income']].values, dtype=torch.float32)\n",
    "\n",
    "# Concatenate the bboxid tensor, temperature tensor, and demographic tensor into a single tensor\n",
    "test_dataset = TensorDataset(torch.cat([bboxid_tensor_test.unsqueeze(-1), temperature_tensor_test, demographic_tensor_test], dim=-1)) \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Concatenate the bboxid tensor, temperature tensor, and demographic tensor into a single tensor\n",
    "test_x = torch.cat([bboxid_tensor_test.unsqueeze(-1), temperature_tensor_test, demographic_tensor_test], dim=-1)\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = likelihood(model(test_x))\n",
    "\n",
    "# with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#     predictions = []\n",
    "#     for batch_x in test_loader:\n",
    "#         batch_x = batch_x[0]\n",
    "#         output = likelihood(model(batch_x))\n",
    "#         predictions.append(output.mean.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homeless_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
